{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Baseline-Code",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wqei_pHop-VtyOkNTz8YXT2PnA81gOf_",
      "authorship_tag": "ABX9TyNDbiH4ZxJX4Zxjwi5nd0v/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walwi878/LSTM-Baseline-Code-Sentiment-Analysis/blob/main/LSTM_Baseline_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn-_iimrJ2y8"
      },
      "source": [
        "#William Wallace\n",
        "#17/03/21\n",
        "#Assignment 1 AIML428 (NLP and Text Mining)\n",
        "#This CNN was build with a lot of help from the following two tutorials: \n",
        "#https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
        "#https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
        "\n",
        "# LSTM and CNN for sequence classification in the IMDB dataset\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Random seed is fixed for repeatability \n",
        "numpy.random.seed(80)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lT5uWNoHByC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fa0135-91ef-4bcd-d292-b4173874c165"
      },
      "source": [
        "# Keeps the top n words for the loaded built-in dataset, and zeros the remaining words\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlwG1smvHF7Y"
      },
      "source": [
        "# Truncates and pads input sequences to ensure vectors are the same size\n",
        "max_review_len = 600\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_len)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS9ErfvVHK2Y",
        "outputId": "2b6eac61-e8d5-4d6b-80ea-a574bfbe7412"
      },
      "source": [
        "# Defines the model's architecture\n",
        "embedding_vector_len = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_len, input_length=max_review_len))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=128)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 600, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 600, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 300, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 216,405\n",
            "Trainable params: 216,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "196/196 [==============================] - 143s 719ms/step - loss: 0.6366 - accuracy: 0.5884\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 141s 720ms/step - loss: 0.2541 - accuracy: 0.8988\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 140s 714ms/step - loss: 0.2010 - accuracy: 0.9241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb303819550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_rR2EpIHPTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48bd0217-ba4b-4dc4-8bab-f25e6cb1fc6a"
      },
      "source": [
        "# Results and accuracy\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.71%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}